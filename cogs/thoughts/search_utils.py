"""
æ¤œç´¢ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
"""

import logging
import os
from typing import List, Dict, Any, Optional
from datetime import datetime

import discord
from discord import app_commands, ui, Interaction, Embed
from discord.ext import commands

# ãƒãƒãƒ¼ã‚¸ãƒ£ãƒ¼ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))
from managers.post_manager import PostManager
from managers.reply_manager import ReplyManager
from managers.like_manager import LikeManager
from managers.message_ref_manager import MessageRefManager
from managers.action_manager import ActionManager
from config import get_channel_id, extract_channel_id

# ãƒ­ã‚¬ãƒ¼è¨­å®š
logger = logging.getLogger(__name__)

# å®šæ•°
MAX_SEARCH_RESULTS = 50
ITEMS_PER_PAGE = 3

# å‹å®šç¾©
PostData = Dict[str, Any]

def search_posts(
    keyword: Optional[str] = None,
    category: Optional[str] = None,
    author_id: Optional[str] = None,
    date_from: Optional[datetime] = None,
    date_to: Optional[datetime] = None,
    is_anonymous: Optional[bool] = None,
    post_manager: Optional[PostManager] = None
) -> List[PostData]:
    """æŠ•ç¨¿ã‚’æ¤œç´¢ã™ã‚‹"""
    if not post_manager:
        return []
    
    try:
        # å…¨æŠ•ç¨¿ã‚’å–å¾—
        all_posts = post_manager.get_all_posts()
        logger.info(f"ğŸ” æ¤œç´¢ãƒ‡ãƒãƒƒã‚°: å…¨æŠ•ç¨¿æ•°={len(all_posts)}")
        
        if not all_posts:
            logger.warning("âš ï¸ æ¤œç´¢ãƒ‡ãƒãƒƒã‚°: æŠ•ç¨¿ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            return []
        
        # æ¤œç´¢æ¡ä»¶ã‚’ãƒ­ã‚°
        logger.info(f"ğŸ” æ¤œç´¢æ¡ä»¶: keyword={keyword}, category={category}, author_id={author_id}")
        
        # æ¤œç´¢æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_posts = []
        for i, post in enumerate(all_posts):
            logger.info(f"ğŸ” æŠ•ç¨¿{i+1}: ID={post.get('id')}, content={post.get('content', '')[:50]}...")
            
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
            if keyword:
                content = post.get('content', '').lower()
                category_match = post.get('category', '').lower()
                keyword_lower = keyword.lower()
                
                content_match = keyword_lower in content
                category_match_result = keyword_lower in category_match
                
                logger.info(f"  - ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢: '{keyword_lower}'")
                logger.info(f"    * content match: {content_match}")
                logger.info(f"    * category match: {category_match_result}")
                
                if not content_match and not category_match_result:
                    logger.info(f"  âŒ ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    continue
                else:
                    logger.info(f"  âœ… ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã«ä¸€è‡´")
            
            # ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¤œç´¢
            if category:
                post_category = post.get('category', '').lower()
                category_lower = category.lower()
                category_match = category_lower in post_category
                
                logger.info(f"  - ã‚«ãƒ†ã‚´ãƒªãƒ¼æ¤œç´¢: '{category_lower}' in '{post_category}' = {category_match}")
                
                if not category_match:
                    logger.info(f"  âŒ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ä¸€è‡´ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    continue
                else:
                    logger.info(f"  âœ… ã‚«ãƒ†ã‚´ãƒªãƒ¼ã«ä¸€è‡´")
            
            # è‘—è€…æ¤œç´¢
            if author_id:
                post_author = post.get('user_id')
                author_match = post_author == author_id
                
                logger.info(f"  - è‘—è€…æ¤œç´¢: {post_author} == {author_id} = {author_match}")
                
                if not author_match:
                    logger.info(f"  âŒ è‘—è€…ã«ä¸€è‡´ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    continue
                else:
                    logger.info(f"  âœ… è‘—è€…ã«ä¸€è‡´")
            
            # ã“ã®æŠ•ç¨¿ã¯å…¨ã¦ã®æ¡ä»¶ã‚’ã‚¯ãƒªã‚¢
            logger.info(f"  âœ… æŠ•ç¨¿ã‚’æ¤œç´¢çµæœã«è¿½åŠ : ID={post.get('id')}")
            filtered_posts.append(post)
            
            # æ—¥ä»˜æ¤œç´¢
            if date_from or date_to:
                try:
                    post_date = datetime.fromisoformat(post.get('created_at', '').replace('Z', '+00:00'))
                    logger.info(f"  - æ—¥ä»˜æ¤œç´¢: {post_date}")
                    
                    if date_from and post_date < date_from:
                        logger.info(f"    âŒ é–‹å§‹æ—¥ã‚ˆã‚Šå‰ã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {post_date} < {date_from}")
                        continue
                    if date_to and post_date > date_to:
                        logger.info(f"    âŒ çµ‚äº†æ—¥ã‚ˆã‚Šå¾Œã®ãŸã‚ã‚¹ã‚­ãƒƒãƒ—: {post_date} > {date_to}")
                        continue
                    
                    logger.info(f"    âœ… æ—¥ä»˜ç¯„å›²å†…")
                except (ValueError, TypeError):
                    logger.warning(f"    âš ï¸ æ—¥ä»˜è§£æã‚¨ãƒ©ãƒ¼: {post.get('created_at')}")
                    continue
            
            # åŒ¿åãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
            if is_anonymous is not None:
                post_anonymous = post.get('is_anonymous', False)
                anonymous_match = post_anonymous == is_anonymous
                
                logger.info(f"  - åŒ¿åãƒ•ã‚£ãƒ«ã‚¿ãƒ¼: {post_anonymous} == {is_anonymous} = {anonymous_match}")
                
                if not anonymous_match:
                    logger.info(f"    âŒ åŒ¿åè¨­å®šãŒä¸€è‡´ã—ãªã„ãŸã‚ã‚¹ã‚­ãƒƒãƒ—")
                    continue
                else:
                    logger.info(f"    âœ… åŒ¿åè¨­å®šãŒä¸€è‡´")
        
        logger.info(f"ğŸ” æ¤œç´¢çµæœ: {len(filtered_posts)}ä»¶ã®æŠ•ç¨¿ãŒä¸€è‡´")
        
        # ä½œæˆæ—¥ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        filtered_posts.sort(
            key=lambda x: datetime.fromisoformat(x.get('created_at', '').replace('Z', '+00:00')),
            reverse=True
        )
        
        return filtered_posts[:MAX_SEARCH_RESULTS]
        
    except Exception as e:
        logger.error(f"æŠ•ç¨¿æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def search_replies(
    keyword: Optional[str] = None,
    author_id: Optional[str] = None,
    date_from: Optional[datetime] = None,
    date_to: Optional[datetime] = None,
    reply_manager: Optional[ReplyManager] = None
) -> List[Dict[str, Any]]:
    """ãƒªãƒ—ãƒ©ã‚¤ã‚’æ¤œç´¢ã™ã‚‹"""
    if not reply_manager:
        return []
    
    try:
        # å…¨ãƒªãƒ—ãƒ©ã‚¤ã‚’å–å¾—
        all_replies = reply_manager.get_all_replies()
        
        # æ¤œç´¢æ¡ä»¶ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered_replies = []
        for reply in all_replies:
            # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰æ¤œç´¢
            if keyword:
                content = reply.get('content', '').lower()
                if keyword.lower() not in content:
                    continue
            
            # è‘—è€…æ¤œç´¢
            if author_id:
                if reply.get('user_id') != author_id:
                    continue
            
            # æ—¥ä»˜æ¤œç´¢
            if date_from or date_to:
                try:
                    reply_date = datetime.fromisoformat(reply.get('created_at', '').replace('Z', '+00:00'))
                    if date_from and reply_date < date_from:
                        continue
                    if date_to and reply_date > date_to:
                        continue
                except (ValueError, TypeError):
                    continue
            
            filtered_replies.append(reply)
        
        # ä½œæˆæ—¥ã§ã‚½ãƒ¼ãƒˆï¼ˆæ–°ã—ã„é †ï¼‰
        filtered_replies.sort(
            key=lambda x: datetime.fromisoformat(x.get('created_at', '').replace('Z', '+00:00')),
            reverse=True
        )
        
        return filtered_replies[:MAX_SEARCH_RESULTS]
        
    except Exception as e:
        logger.error(f"ãƒªãƒ—ãƒ©ã‚¤æ¤œç´¢ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")
        return []

def create_search_embed(
    results: List[Dict[str, Any]],
    search_type: str,
    page: int = 1,
    total_pages: int = 1
) -> Embed:
    """æ¤œç´¢çµæœã®Embedã‚’ä½œæˆ"""
    embed = discord.Embed(
        title=f"ğŸ” {search_type}æ¤œç´¢çµæœ",
        color=discord.Color.blue()
    )
    
    if not results:
        embed.description = "æ¤œç´¢çµæœãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚"
        embed.add_field(
            name="ğŸ’¡ ãƒ’ãƒ³ãƒˆ",
            value="â€¢ ç•°ãªã‚‹ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã‚’è©¦ã—ã¦ãã ã•ã„\nâ€¢ ã‚«ãƒ†ã‚´ãƒªãƒ¼ã§çµã‚Šè¾¼ã‚“ã§ã¿ã¦ãã ã•ã„\nâ€¢ æ—¥ä»˜ç¯„å›²ã‚’èª¿æ•´ã—ã¦ã¿ã¦ãã ã•ã„",
            inline=False
        )
        return embed
    
    # çµæœã‚’è¡¨ç¤º
    start_idx = (page - 1) * ITEMS_PER_PAGE
    end_idx = start_idx + ITEMS_PER_PAGE
    page_results = results[start_idx:end_idx]
    
    for i, item in enumerate(page_results, start=start_idx + 1):
        if search_type == "æŠ•ç¨¿":
            content = item.get('content', '')[:200] + "..." if len(item.get('content', '')) > 200 else item.get('content', '')
            category = item.get('category', 'æœªåˆ†é¡')
            post_id = item.get('id', 'ä¸æ˜')
            created_at = item.get('created_at', 'ä¸æ˜')
            is_anonymous = item.get('is_anonymous', False)
            
            author = "åŒ¿å" if is_anonymous else f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {item.get('user_id', 'ä¸æ˜')}"
            
            field_name = f"ğŸ“ {i}. æŠ•ç¨¿ID: {post_id}"
            field_value = f"**è‘—è€…:** {author}\n**ã‚«ãƒ†ã‚´ãƒªãƒ¼:** {category}\n**å†…å®¹:** {content}\n**ä½œæˆæ—¥:** {created_at}"
            
        elif search_type == "ãƒªãƒ—ãƒ©ã‚¤":
            content = item.get('content', '')[:200] + "..." if len(item.get('content', '')) > 200 else item.get('content', '')
            reply_id = item.get('id', 'ä¸æ˜')
            post_id = item.get('post_id', 'ä¸æ˜')
            created_at = item.get('created_at', 'ä¸æ˜')
            
            field_name = f"ğŸ’¬ {i}. ãƒªãƒ—ãƒ©ã‚¤ID: {reply_id}"
            field_value = f"**æŠ•ç¨¿ID:** {post_id}\n**å†…å®¹:** {content}\n**ä½œæˆæ—¥:** {created_at}\n**è‘—è€…:** ãƒ¦ãƒ¼ã‚¶ãƒ¼ID: {item.get('user_id', 'ä¸æ˜')}"
        
        embed.add_field(
            name=field_name,
            value=field_value,
            inline=False
        )
    
    # ãƒ•ãƒƒã‚¿ãƒ¼æƒ…å ±
    embed.set_footer(
        text=f"ãƒšãƒ¼ã‚¸ {page}/{total_pages} | å…¨{len(results)}ä»¶ã®çµæœ"
    )
    
    return embed

def parse_date_string(date_str: str) -> Optional[datetime]:
    """æ—¥ä»˜æ–‡å­—åˆ—ã‚’è§£æ"""
    try:
        # YYYY-MM-DDå½¢å¼ã‚’è§£æ
        if len(date_str) == 10 and date_str.count('-') == 2:
            return datetime.strptime(date_str, '%Y-%m-%d')
        
        # ãã®ä»–ã®å½¢å¼ã‚’è©¦ã™
        formats = ['%Y/%m/%d', '%Y-%m-%d %H:%M', '%Y/%m/%d %H:%M']
        for fmt in formats:
            try:
                return datetime.strptime(date_str, fmt)
            except ValueError:
                continue
        
        return None
    except Exception:
        return None

def validate_search_params(
    keyword: Optional[str],
    category: Optional[str],
    date_from_str: Optional[str],
    date_to_str: Optional[str]
) -> tuple[bool, str]:
    """æ¤œç´¢ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ã‚’æ¤œè¨¼"""
    # æ—¥ä»˜ã®æ¤œè¨¼
    date_from = None
    date_to = None
    
    if date_from_str:
        date_from = parse_date_string(date_from_str)
        if not date_from:
            return False, "é–‹å§‹æ—¥ä»˜ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    
    if date_to_str:
        date_to = parse_date_string(date_to_str)
        if not date_to:
            return False, "çµ‚äº†æ—¥ä»˜ã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚YYYY-MM-DDå½¢å¼ã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    
    # æ—¥ä»˜ç¯„å›²ã®æ¤œè¨¼
    if date_from and date_to:
        if date_from > date_to:
            return False, "é–‹å§‹æ—¥ä»˜ã¯çµ‚äº†æ—¥ä»˜ã‚ˆã‚Šå‰ã«ã—ã¦ãã ã•ã„ã€‚"
    
    # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æ¤œè¨¼
    if keyword and len(keyword.strip()) < 2:
        return False, "ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã¯2æ–‡å­—ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    
    # ã‚«ãƒ†ã‚´ãƒªãƒ¼ã®æ¤œè¨¼
    if category and len(category.strip()) < 2:
        return False, "ã‚«ãƒ†ã‚´ãƒªãƒ¼ã¯2æ–‡å­—ä»¥ä¸Šã§å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚"
    
    return True, ""
